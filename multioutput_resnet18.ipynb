{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzK__LLLzRPG"
      },
      "source": [
        "Install dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGOV9TZ8zYzH"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install Pillow\n",
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cqzx9MHdzXj8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTSm4pA10SLj"
      },
      "source": [
        "download the dataset from drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZpzr5a50VRf"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/data_lego.zip' -d '/content/data'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcKfRPU93RUj"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgjNxB9E1y0z"
      },
      "source": [
        "code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JTiv3XA014l6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "import argparse\n",
        "import glob\n",
        "import datetime\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import imgaug.augmenters as iaa\n",
        "import imgaug as ia\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Configuration\n",
        "class Config:\n",
        "    OUTPUT = \"/content/drive/MyDrive\"\n",
        "    DATASET_PATH = \"/content/data\"\n",
        "    LABELS_PATH = os.path.join(DATASET_PATH, \"data.csv\")\n",
        "    IMAGES_PATH = os.path.join(DATASET_PATH, \"images\")\n",
        "    SUMMARY_PATH = os.path.join(DATASET_PATH, \"summary\")\n",
        "    DEBUG_PATH = os.path.join(DATASET_PATH, \"examples\")\n",
        "    IMAGE_RESIZE = 224\n",
        "    AUGMENTATION_FACTOR = 5\n",
        "    TRAIN_SPLIT= 0.8\n",
        "    BATCH_SIZE = 10\n",
        "    FREEZE_BACKBONE = True\n",
        "    EPOCHS = 20\n",
        "    DEBUG = True\n",
        "    MODEL_NAME = \"ckpt_{epoch:d}_{loss:f}.pth\"\n",
        "    CKPT_SAVE_INTERVAL = 5\n",
        "    LR = 1e-3\n",
        "    EPS = 1e-6\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "rHMVYOQKxRTU"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Define the dataset class\n",
        "class LegoDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, root_dir, transform=None, do_aug=False, augmentation_factor=1):\n",
        "        self.data = pd.read_csv(os.path.join(root_dir,csv_file))\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.do_aug = do_aug\n",
        "        self.brick_type_dict = {\n",
        "                        '6*2': 0,\n",
        "                        '3*1': 1,\n",
        "                        '3*2': 2,\n",
        "                        '2*1': 3,\n",
        "                        '4*2': 4,\n",
        "                        '1*1': 5,\n",
        "                        '8*2': 6,\n",
        "                        '4*1': 7,\n",
        "                        '2*1_pyramid': 8,\n",
        "                        '2*2': 9,\n",
        "                        '6*1': 10\n",
        "                    }\n",
        "        self.seq_train = iaa.Sequential([\n",
        "            iaa.CropAndPad(percent=(0, 0.1)),\n",
        "            iaa.Affine(rotate=(-20, 20)),\n",
        "            iaa.Resize({\"height\": Config.IMAGE_RESIZE, \"width\": Config.IMAGE_RESIZE}),\n",
        "            iaa.MultiplyAndAddToBrightness(mul=(0.5, 1.5), add=(-30, 30)),\n",
        "            iaa.GammaContrast((0.5, 2.0), per_channel=True),\n",
        "            iaa.GaussianBlur((0, 3.0))\n",
        "        ])\n",
        "\n",
        "        self.seq_test = iaa.Sequential([\n",
        "            iaa.Resize({\"height\": Config.IMAGE_RESIZE, \"width\": Config.IMAGE_RESIZE})\n",
        "        ])\n",
        "\n",
        "        self.augmentation_factor = augmentation_factor\n",
        "        self.do_aug = do_aug\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) * self.augmentation_factor\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        # Determine the original index in the annotations\n",
        "        original_index = idx // self.augmentation_factor\n",
        "        sample = self.data.iloc[original_index]\n",
        "\n",
        "        img_name = sample['filename']\n",
        "        img_path = os.path.join(self.root_dir,'images', img_name + '.png')\n",
        "        image = np.array(Image.open(img_path))[..., :3]\n",
        "\n",
        "        # Extract target variables\n",
        "        brick_type = self.brick_type_dict[sample['brick_type']]\n",
        "\n",
        "        rotation_x = sample['rotation_x']\n",
        "        rotation_y = sample['rotation_y']\n",
        "        rotation_z = sample['rotation_z']\n",
        "\n",
        "        color_r = sample['color_r']\n",
        "        color_g = sample['color_g']\n",
        "        color_b = sample['color_b']\n",
        "\n",
        "        \n",
        "        # Apply augmentations\n",
        "        if self.do_aug:\n",
        "            image = self.seq_train(image=image)\n",
        "        else :\n",
        "            image = self.seq_test(image=image)\n",
        "        \n",
        "        image = Image.fromarray(image)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return (\n",
        "            image,\n",
        "            torch.tensor(brick_type).long(),\n",
        "            torch.tensor(rotation_x).float(),\n",
        "            torch.tensor(rotation_y).float(),\n",
        "            torch.tensor(rotation_z).float(),\n",
        "            torch.tensor(color_r).float(),\n",
        "            torch.tensor(color_g).float(),\n",
        "            torch.tensor(color_b).float()\n",
        "        )\n",
        "\n",
        "# The sections for Model, Training, and Evaluation will be added next...\n",
        "\n",
        "# Multi-output ResNet Model\n",
        "class LegoModel(nn.Module):\n",
        "    def __init__(self, num_brick_types = 11, inference = True):\n",
        "        super(LegoModel, self).__init__()\n",
        "\n",
        "        self.inference = inference\n",
        "\n",
        "        # Load ResNet18 pre-trained on ImageNet\n",
        "        model = models.resnet18(pretrained=True)\n",
        "\n",
        "        self.backbone = nn.Sequential(\n",
        "            model.conv1, \n",
        "            model.bn1, \n",
        "            model.relu, \n",
        "            model.maxpool, \n",
        "            model.layer1, \n",
        "            model.layer2, \n",
        "            model.layer3, \n",
        "            model.layer4\n",
        "        )\n",
        "        \n",
        "        # Modify the final layer to handle multiple outputs\n",
        "        num_features = model.fc.in_features\n",
        "        \n",
        "        # Freeze backbone\n",
        "        # optional for speed or few-shot-learning\n",
        "        if Config.FREEZE_BACKBONE :\n",
        "            for param in self.backbone.parameters() :\n",
        "                param.requires_grad = False\n",
        "        \n",
        "        # Define the new final layers for our multi-output prediction\n",
        "        self.fc_brick_type = nn.Linear(num_features, num_brick_types)\n",
        "        self.fc_rotation = nn.Linear(num_features, 3)\n",
        "        self.fc_color = nn.Linear(num_features, 3)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x.mean(dim=(2, 3))\n",
        "\n",
        "        brick_type = self.fc_brick_type(x)\n",
        "        rotation = self.fc_rotation(x)\n",
        "        color = self.fc_color(x)\n",
        "\n",
        "        if self.inference:\n",
        "            brick_type = torch.softmax(brick_type, dim=1)\n",
        "            rotation = torch.sigmoid(rotation)\n",
        "            color = torch.sigmoid(color)\n",
        "\n",
        "        return brick_type, rotation, color\n",
        "\n",
        "\n",
        "\n",
        "# Training and Evaluation Functions\n",
        "\n",
        "def train(model, data_loader, optimizer, device, epoch):\n",
        "\n",
        "    data_loader.dataset.dataset.do_aug = True\n",
        "    data_loader.dataset.dataset.augmentation_factor = Config.AUGMENTATION_FACTOR\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    train_loss_brick_type = 0.0\n",
        "    train_loss_rotation = 0.0\n",
        "    train_loss_color = 0.0\n",
        "    train_loss = 0.0\n",
        "    \n",
        "    pbar = tqdm(data_loader)\n",
        "\n",
        "    for batch_idx, (\n",
        "        image,\n",
        "        brick_type,\n",
        "        rotation_x,\n",
        "        rotation_y,\n",
        "        rotation_z,\n",
        "        color_r,\n",
        "        color_g,\n",
        "        color_b\n",
        "\n",
        "    ) in enumerate(pbar, 0):\n",
        "        \n",
        "        image = image.to(device)\n",
        "        brick_type = brick_type.to(device)\n",
        "        rotation = torch.stack((rotation_x, rotation_y, rotation_z), dim=1).to(device)\n",
        "        color = torch.stack((color_r, color_g, color_b), dim=1).to(device)\n",
        "        \n",
        "        # Optimizer zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Model inference\n",
        "        out_brick_type, out_rotation, out_color = model(image)\n",
        "        \n",
        "        # Calculate loss\n",
        "        loss_brick = criterion_brick_type(out_brick_type, brick_type)\n",
        "        loss_rotation = criterion_values(out_rotation, rotation)\n",
        "        loss_color = criterion_values(out_color, color)\n",
        "        loss = 1 * loss_brick + 1 * loss_rotation + 1 * loss_color # we could penalize more each parameter\n",
        "        \n",
        "        pbar.set_description(f\"TRAIN loss={float(loss)} | loss_brick={float(loss_brick)} | loss_rotation={float(loss_rotation)} | loss_color={float(loss_color)}\")\n",
        "\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        \n",
        "        # Optimizer\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss_brick_type += loss_brick.item()\n",
        "        train_loss_rotation += loss_rotation.item()\n",
        "        train_loss_color += loss_color.item()\n",
        "        train_loss += loss.item()\n",
        "        \n",
        "    loss_brick_type = train_loss_brick_type / len(data_loader)\n",
        "    loss_rotation = train_loss_rotation / len(data_loader)\n",
        "    loss_color = train_loss_color / len(data_loader)\n",
        "    avg_loss = train_loss / len(data_loader)\n",
        "\n",
        "    return avg_loss, loss_brick_type, loss_rotation, loss_color\n",
        "\n",
        "def test(model, data_loader, device, epoch):\n",
        "\n",
        "    data_loader.dataset.dataset.do_aug = False\n",
        "    data_loader.dataset.dataset.augmentation_factor = 1\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    test_loss_brick_type = 0.0\n",
        "    test_loss_rotation = 0.0\n",
        "    test_loss_color = 0.0\n",
        "    test_loss = 0.0\n",
        "    \n",
        "    # Initialize accumulators\n",
        "    total_type_correct = 0\n",
        "    total_rotation_mae = np.zeros(3)\n",
        "    total_rotation_mse = np.zeros(3)\n",
        "    total_color_mae = np.zeros(3)\n",
        "    total_color_mse = np.zeros(3)\n",
        "\n",
        "    pbar = tqdm(data_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for batch_idx, (\n",
        "            image,\n",
        "            brick_type,\n",
        "            rotation_x,\n",
        "            rotation_y,\n",
        "            rotation_z,\n",
        "            color_r,\n",
        "            color_g,\n",
        "            color_b\n",
        "\n",
        "        ) in enumerate(pbar, 0):\n",
        "            \n",
        "            image = image.to(device)\n",
        "            brick_type = brick_type.to(device)\n",
        "            rotation = torch.stack((rotation_x, rotation_y, rotation_z), dim=1).to(device)\n",
        "            color = torch.stack((color_r, color_g, color_b), dim=1).to(device)\n",
        "       \n",
        "            # Forward pass\n",
        "            out_brick_type, out_rotation, out_color = model(image)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss_brick = criterion_brick_type(out_brick_type, brick_type)\n",
        "            loss_rotation = criterion_values(out_rotation, rotation)\n",
        "            loss_color = criterion_values(out_color, color)\n",
        "            loss = 1 * loss_brick + 1 * loss_rotation + 1 * loss_color\n",
        "\n",
        "            pbar.set_description(f\"TEST loss={float(loss)} | loss_brick={float(loss_brick)} | loss_rotation={float(loss_rotation)} | loss_color={float(loss_color)}\")\n",
        "\n",
        "            test_loss_brick_type += loss_brick.item()\n",
        "            test_loss_rotation += loss_rotation.item()\n",
        "            test_loss_color += loss_color.item()\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # total_type_correct\n",
        "            # total_rotation_mae\n",
        "            # total_rotation_mse\n",
        "            # total_color_mae\n",
        "            # total_color_mse\n",
        "\n",
        "            # Gender accuracy\n",
        "            type_correct = (torch.argmax(out_brick_type, dim=1) == brick_type).float().sum()\n",
        "            total_type_correct += type_correct\n",
        "\n",
        "            # # Age metrics\n",
        "            # age_diff = np.array(true_age) - np.array(pred_age)\n",
        "            # total_age_mae += np.sum(np.abs(age_diff))\n",
        "            # total_age_mse += np.sum(age_diff**2)\n",
        "\n",
        "            # # Eye position metrics\n",
        "            # eye_position_diff = np.array(true_eye) - np.array(pred_eye)\n",
        "            # total_eye_position_mae += np.sum(np.abs(eye_position_diff), axis=0)\n",
        "            # total_eye_position_mse += np.sum(eye_position_diff**2, axis=0)\n",
        "\n",
        "    loss_brick = test_loss_brick_type / len(data_loader)\n",
        "    loss_rotation = test_loss_rotation / len(data_loader)\n",
        "    loss_color = test_loss_color / len(data_loader)\n",
        "    avg_loss = test_loss / len(data_loader)\n",
        "\n",
        "    return avg_loss, loss_brick, loss_rotation, loss_color, type_correct\n",
        "\n",
        "def criterion_values(pred, true):\n",
        "    return F.mse_loss(torch.sigmoid(pred), true)\n",
        "  \n",
        "criterion_brick_type = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8OBB4Ahxdu5"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main(experiment):\n",
        "\n",
        "\n",
        "    # define Device\n",
        "    if torch.cuda.is_available():\n",
        "      device = torch.device(\"cuda\")\n",
        "      print(\"CUDA is available. Using GPU.\")\n",
        "    else:\n",
        "      device = torch.device(\"cpu\")\n",
        "      print(\"CUDA is not available. Using CPU.\")\n",
        "    \n",
        "    # Create project folder and names\n",
        "    OUTPUT_FOLDER = os.path.join(Config.OUTPUT, experiment, datetime.datetime.now().strftime(\"%d_%m_%Y__%H_%M_%S\"))\n",
        "    os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
        "    print('OUTPUT_FOLDER',OUTPUT_FOLDER)\n",
        "\n",
        "\n",
        "\n",
        "    os.makedirs(Config.SUMMARY_PATH, exist_ok=True)\n",
        "    os.makedirs(Config.DEBUG_PATH, exist_ok=True)\n",
        "\n",
        "    CHECKPOINTS_FOLDER = os.path.join(OUTPUT_FOLDER, 'checkpoints')\n",
        "    os.makedirs(CHECKPOINTS_FOLDER, exist_ok=True)\n",
        "    \n",
        "    # Define the data transformations\n",
        "    data_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # Define the dataset and data loader\n",
        "    lego_dataset = LegoDataset('data.csv', './data', transform=data_transform)\n",
        "    train_size = int(Config.TRAIN_SPLIT * len(lego_dataset))\n",
        "    test_size = len(lego_dataset) - train_size\n",
        "    print('train_size',train_size)\n",
        "    print('test_size',test_size)\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(lego_dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Initialize the model and define the loss function and optimizer\n",
        "    model = LegoModel(inference=False)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=Config.LR, eps = Config.EPS)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Epochs\n",
        "    best_val_loss = float('inf')\n",
        "    best_epoch = 0\n",
        "    best_model = None\n",
        "    best_type_accuracy = None\n",
        "    best_rotation_mae = None\n",
        "    best_rotation_rmse = None\n",
        "    best_color_mae = None\n",
        "    best_color_rmse = None\n",
        "\n",
        "    # Initialize accumulators\n",
        "    train_losses = []\n",
        "    train_losses_type = []\n",
        "    train_losses_rotation = []\n",
        "    train_losses_color = []\n",
        "\n",
        "    val_losses = []\n",
        "    val_losses_type = []\n",
        "    val_losses_rotation = []\n",
        "    val_losses_color = []\n",
        "\n",
        "    epochs_type_accuracy  = []\n",
        "    epochs_rotation_mae  = []\n",
        "    epochs_rotation_rmse  = []\n",
        "    epochs_color_mae  = []\n",
        "    epochs_color_rmse  = []\n",
        "\n",
        "    # writer = SummaryWriter()\n",
        "\n",
        "    # Train the model\n",
        "    for epoch in range(Config.EPOCHS):\n",
        "        (\n",
        "            train_loss, \n",
        "            train_loss_brick_type, \n",
        "            train_loss_rotation, \n",
        "            train_loss_color \n",
        "        ) = train(model, train_loader, optimizer, device, epoch)\n",
        "        \n",
        "        (\n",
        "            val_loss, \n",
        "            val_loss_brick, \n",
        "            val_loss_rotation, \n",
        "            val_loss_color, \n",
        "            total_type_correct\n",
        "        ) = test(model, test_loader, device, epoch)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_losses_type.append(train_loss_brick_type)\n",
        "        train_losses_rotation.append(train_loss_rotation)\n",
        "        train_losses_color.append(train_loss_color)\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "        val_losses_type.append(val_loss_brick)\n",
        "        val_losses_rotation.append(val_loss_rotation)\n",
        "        val_losses_color.append(val_loss_color)\n",
        "        \n",
        "        # Compute average metrics for the epoch\n",
        "        epoch_type_accuracy = total_type_correct / len(lego_dataset) * 100\n",
        "\n",
        "\n",
        "        if epoch > 0 and epoch % Config.CKPT_SAVE_INTERVAL == 0 :\n",
        "            print(f\"Saved checkpoint {epoch}\\n\")\n",
        "            model_path_solve = os.path.join(CHECKPOINTS_FOLDER, f\"ckpt_{epoch}_{val_loss}.pth\")\n",
        "            optimizer_path_solve = os.path.join(CHECKPOINTS_FOLDER, model_path_solve.replace('ckpt_', 'optim_'))\n",
        "            torch.save(model.state_dict(), model_path_solve)\n",
        "            torch.save(optimizer.state_dict(), optimizer_path_solve)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_epoch = epoch\n",
        "            best_model = model.state_dict()\n",
        "            best_gender_accuracy = epoch_type_accuracy\n",
        "            \n",
        "        # Print progress\n",
        "        print(f\"Epoch {epoch + 1}/{Config.EPOCHS}\\n\"\n",
        "            \n",
        "            f\"Train Loss (Brick_type): {train_loss_brick_type:.4f}, \"\n",
        "            f\"Train Loss (Rotation): {train_loss_rotation:.4f}, \"\n",
        "            f\"Train Loss (Color): {train_loss_color:.4f}\\n \"\n",
        "\n",
        "            f\"Validation Loss (Brick_type): {val_loss_brick:.4f}, \"\n",
        "            f\"Validation Loss (Rotation): {val_loss_rotation:.4f},\"\n",
        "            f\"Validation Loss (Color): {val_loss_color:.4f}\\n\"\n",
        "\n",
        "            f\"Type accuracy: {epoch_type_accuracy:.2f}%\\n\"\n",
        "        )\n",
        "    \n",
        "    # Save the best model\n",
        "    torch.save(best_model, \"best_{}_{}.pth\".format(best_epoch, best_val_loss))\n",
        "\n",
        "    # Plot the learning curves\n",
        "    epochs = range(1, Config.EPOCHS + 1)\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    plt.subplot(1, 4, 1)\n",
        "    plt.plot(epochs, train_losses_type, label=\"Training\")\n",
        "    plt.plot(epochs, val_losses_type, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Type Output Learning Curve\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 2)\n",
        "    plt.plot(epochs, train_losses_rotation, label=\"Training\")\n",
        "    plt.plot(epochs, val_losses_rotation, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Rotation Output Learning Curve\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 3)\n",
        "    plt.plot(epochs, train_losses_color, label=\"Training\")\n",
        "    plt.plot(epochs, val_losses_color, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Color Output Learning Curve\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 4, 4)\n",
        "    plt.plot(epochs, train_losses, label=\"Training\")\n",
        "    plt.plot(epochs, val_losses, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Global Output Learning Curve\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QwG_zQqk35Y-"
      },
      "outputs": [],
      "source": [
        "main('model_lego_sorter')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
